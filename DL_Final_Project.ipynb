{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bce4ca25cfe8270",
      "metadata": {
        "id": "bce4ca25cfe8270"
      },
      "source": [
        "# DL final project\n",
        "*   Alon Meirovich, ID: 330181470\n",
        "*   Matan Goldfarb, ID: 314623174\n",
        "*   Talya Yermiahu, ID: 207594193"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports\n"
      ],
      "metadata": {
        "id": "0mu2nGLX6wCR"
      },
      "id": "0mu2nGLX6wCR"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "dbbf42fe752a662d",
      "metadata": {
        "id": "dbbf42fe752a662d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9288328-a06b-4b7e-d5fc-8fc61ea5d511"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import Normalize\n",
        "from torchvision.transforms import Grayscale, Resize\n",
        "import time\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/DL Final Project')\n",
        "\n",
        "from project_utils import CombinedDataset, eval_model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training Mode\n"
      ],
      "metadata": {
        "id": "VXHPh1HQx_mf"
      },
      "id": "VXHPh1HQx_mf"
    },
    {
      "cell_type": "code",
      "source": [
        "is_traiting = False"
      ],
      "metadata": {
        "id": "97aSZOJdx7iG"
      },
      "id": "97aSZOJdx7iG",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Section"
      ],
      "metadata": {
        "id": "Xt8yaBUoyZg-"
      },
      "id": "Xt8yaBUoyZg-"
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "batch_size = 64\n",
        "\n",
        "# Transformers\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,)),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomAffine(degrees=(-10, 10), translate=(0.01, 0.15),\n",
        "                            scale=(0.9, 1.1), fill=-1)\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,)),\n",
        "    transforms.Grayscale(),\n",
        "])\n",
        "\n",
        "transform_ood = transforms.Compose([\n",
        "    transforms.Resize((28, 28)),\n",
        "    transforms.Grayscale(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load dataset\n",
        "mnist_train = datasets.MNIST(root='./data', train=True, transform=transform_train, download=True)\n",
        "mnist_test = datasets.MNIST(root='./data', train=False, transform=transform_test, download=True)\n",
        "\n",
        "# Split the train set into train and validation sets\n",
        "train_size = int(0.8 * len(mnist_train))\n",
        "val_size = len(mnist_train) - train_size\n",
        "mnist_train, mnist_val = random_split(mnist_train, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(mnist_val, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False)\n",
        "# Load OOD datasets for testing\n",
        "cifar10 = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_ood)\n",
        "fashion_mnist = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform_ood)\n",
        "# Concatenate CIFAR-10 and FashionMNIST datasets\n",
        "ood_dataset = ConcatDataset([cifar10, fashion_mnist])\n",
        "\n",
        "# Combine MNIST test set with CIFAR-10 and FashionMNIST as OOD data\n",
        "combined_test_loader = DataLoader(CombinedDataset(mnist_test, fashion_mnist), batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5czUBdU8yY0X",
        "outputId": "359c6b0f-6202-45c9-ab7a-4a6d148495f9"
      },
      "id": "5czUBdU8yY0X",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Class\n"
      ],
      "metadata": {
        "id": "D5cmf6ay63h4"
      },
      "id": "D5cmf6ay63h4"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f87848482bc8203c",
      "metadata": {
        "id": "f87848482bc8203c"
      },
      "outputs": [],
      "source": [
        "# Model Class\n",
        "class OSRCNN(nn.Module):\n",
        "    def __init__(self, th):\n",
        "        super(OSRCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 11)  # 10 classes + 1 unknown\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        self.th = th\n",
        "        self.valMode = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        if not self.training and not self.valMode:\n",
        "            with torch.no_grad():\n",
        "                x = self.softmax(x)\n",
        "                probas, y_pred = torch.max(x, 1)\n",
        "                y_pred[probas < self.th] = 10\n",
        "                return y_pred\n",
        "        return x\n",
        "\n",
        "    def set_validation(self, val_mode):\n",
        "        self.valMode = val_mode\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Useful Functions\n"
      ],
      "metadata": {
        "id": "zN40G7o37CCi"
      },
      "id": "zN40G7o37CCi"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a90b8eb5fd59b8e7",
      "metadata": {
        "id": "a90b8eb5fd59b8e7"
      },
      "outputs": [],
      "source": [
        "# Training the OSR model\n",
        "def train_osr(model, train_loader, criterion, optimizer, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        norm_loss = running_loss/len(train_loader)\n",
        "    print(f\"Epoch {epoch+1}, Loss: {norm_loss}\")\n",
        "    return norm_loss\n",
        "\n",
        "# Validation function for the OSR model\n",
        "def validate_osr(model, val_loader, criterion):\n",
        "    model.eval()\n",
        "    model.set_validation(True)\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            norm_val_loss = val_loss/len(val_loader)\n",
        "    print(f\"Validation Loss: {norm_val_loss}\")\n",
        "    model.set_validation(False)\n",
        "    return norm_val_loss\n",
        "\n",
        "def plot_accuracy(train_accuracies, val_accuracies):\n",
        "    plt.plot(train_accuracies, label='Training accuracy')\n",
        "    plt.plot(val_accuracies, label='Validation accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_predictions(model, loader, class_names):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            plt.figure(figsize=(10, 4))\n",
        "            for i in range(10):\n",
        "                plt.subplot(2, 5, i + 1)\n",
        "                plt.imshow(inputs[i].cpu().squeeze(), cmap='gray')\n",
        "                plt.axis('off')\n",
        "                if outputs[i] == len(class_names):\n",
        "                    plt.title(f'Pred: Unknown, Actual: {class_names[labels[i]]}')\n",
        "                else:\n",
        "                    plt.title(f'Pred: {class_names[outputs[i]]}, Actual: {class_names[labels[i]]}')\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "            break\n",
        "\n",
        "\n",
        "def plot_loss(loss, num):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(range(1, len(loss) + 1), loss)\n",
        "    if num == 1:\n",
        "        plt.title('Training Loss Over Epochs')\n",
        "    elif num == 2:\n",
        "        plt.title('Validation Loss Over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def show_images(images, titles=None):\n",
        "    fig, axs = plt.subplots(1, len(images), figsize=(15, 15))\n",
        "    for i, img in enumerate(images):\n",
        "        axs[i].imshow(img.view(28, 28).cpu().detach().numpy(), cmap='gray')\n",
        "        if titles:\n",
        "            axs[i].set_title(titles[i])\n",
        "        axs[i].axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Process\n"
      ],
      "metadata": {
        "id": "Nt7-NG437npO"
      },
      "id": "Nt7-NG437npO"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2b10950bad8c2bd5",
      "metadata": {
        "id": "2b10950bad8c2bd5"
      },
      "outputs": [],
      "source": [
        "# Train the OSR model\n",
        "\n",
        "if is_traiting:\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(f\"Using device: {device}\")\n",
        "\n",
        "  epochs = 30\n",
        "  lr = 0.001\n",
        "  # Initialization\n",
        "  torch.manual_seed(42)\n",
        "  model = OSRCNN(0).to(device)\n",
        "  osr_criterion = nn.CrossEntropyLoss()\n",
        "  osr_optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "  # Training\n",
        "  train_losses = []\n",
        "  val_losses = []\n",
        "  time_0 = time.time()\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      train_losses.append(train_osr(model, train_loader, osr_criterion, osr_optimizer, epoch))\n",
        "      val_losses.append(validate_osr(model, val_loader, osr_criterion))\n",
        "      # Save the OSR model\n",
        "      model_filename = f'osr_soft00001_model_epoch_{epoch + 1}.pth'\n",
        "      torch.save(model.state_dict(), model_filename)\n",
        "\n",
        "\n",
        "  print(\"Total run-time: %s seconds\" % (time.time() - time_0))\n",
        "\n",
        "  class_names = [str(i) for i in range(10)] + [\"Unknown\"]\n",
        "  plot_predictions(model, train_loader, class_names)\n",
        "  plot_loss(train_losses, 1), plot_loss(val_losses, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate OSR model\n"
      ],
      "metadata": {
        "id": "5uAqGcKc7_oO"
      },
      "id": "5uAqGcKc7_oO"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "OqIrQr5WrQPa",
      "metadata": {
        "id": "OqIrQr5WrQPa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6974e3c-f115-480d-c153-709a65273cbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNIST Accuracy: 94.96%\n",
            "OOD Accuracy: 96.14%\n",
            "Total Accuracy: 95.55%\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the OSR model\n",
        "# Loading the saved OSR model\n",
        "th = 0.99\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "osr_model_loaded = OSRCNN(th).to(device)\n",
        "osr_model_loaded.load_state_dict(torch.load('osr_model_epoch_30.pth', map_location=device))\n",
        "osr_model_loaded.eval()\n",
        "acc_mnist, acc_ood, acc_total = eval_model(osr_model_loaded, combined_test_loader, device)\n",
        "print(f'MNIST Accuracy: {acc_mnist*100:.2f}%')\n",
        "print(f'OOD Accuracy: {acc_ood*100:.2f}%')\n",
        "print(f'Total Accuracy: {acc_total*100:.2f}%')\n",
        "\n",
        "# So after ±50 runs this model approaches a 96% of accuracy, with another model we may get more!!\n",
        "# There won't be no time limit for training, just for test\n",
        "# Ask Ron how many pics will be on test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate BaseLine model"
      ],
      "metadata": {
        "id": "QgwZwd2X8Ywt"
      },
      "id": "QgwZwd2X8Ywt"
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the OSR model\n",
        "# Loading the saved OSR model\n",
        "th = 0\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "baseLine_model_loaded = OSRCNN(th).to(device)\n",
        "baseLine_model_loaded.load_state_dict(torch.load('osr_model_epoch_30.pth', map_location=device))\n",
        "baseLine_model_loaded.eval()\n",
        "acc_mnist, acc_ood, acc_total = eval_model(baseLine_model_loaded, test_loader, device)\n",
        "print(f'MNIST Accuracy: {acc_mnist*100:.2f}%')\n",
        "print(f'Total Accuracy: {acc_total*100:.2f}%')\n",
        "\n",
        "# So after ±50 runs this model approaches a 96% of accuracy, with another model we may get more!!\n",
        "# There won't be no time limit for training, just for test\n",
        "# Ask Ron how many pics will be on test"
      ],
      "metadata": {
        "id": "JYvstXmTMdTg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dbb732b-99ba-43d3-ff2a-84092f3286e4"
      },
      "id": "JYvstXmTMdTg",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNIST Accuracy: 99.29%\n",
            "Total Accuracy: 99.29%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}